# Context Tokens are Anchors: Understanding the Repeat Curse in dMLLMs from an Information Flow Perspective

[![arXiv](https://img.shields.io/badge/Arxiv-2410.15926-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2601.20520) <a href="https://arxiv.org/abs/2601.20520"></a> 


> **[Context Tokens are Anchors: Understanding the Repeat Curse in dMLLMs from an Information Flow Perspective](https://arxiv.org/abs/2601.20520)**<br>
> ICLR 2026<br>
> Qiyan Zhao, Xiaofeng Zhang, Shuochen Chang, Qianyu Chen, Xiaosong Yuan, Xuhang Chen, Luoqi Liu, Jiajun Zhang, Xu-Yao Zhang, Da-Han Wang<br>



## üõ†Ô∏è Install
```
git clone https://github.com/ErikZ719/CoTA
cd CoTA/train
bash init_env.sh
python generate_demo.py
```


## Citation
```bibtex
@inproceedings{zhao2026context,
  title={Context Tokens are Anchors: Understanding the Repeat Curse in dMLLMs from an Information Flow Perspective},
  author={Zhao, Qiyan and Zhang, Xiaofeng and Chang, Shuochen and Chen, Qianyu and Yuan, Xiaosong and Chen, Xuhang and Liu, Luoqi and Zhang, Jiajun and Zhang, Xu-Yao and Wang, Da-Han},
  booktitle={The Fourteenth International Conference on Learning Representations (ICLR)},
  year={2026}
}
```
## Acknowledgement

This repo is built on [LLaDA-V](https://github.com/ML-GSAI/LLaDA-V) (models) and [dLLM-Cache]([[https://github.com/pkunlp-icler/FastV](https://github.com/xing0047/cca-llava](https://github.com/maomaocun/dLLM-cache/tree/main))) . Many thanks for their efforts. The use of our code should also follow the original licenses.
